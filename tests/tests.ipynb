{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hackathon\n",
    "* integrate custom functions for NA value & change_dtype\n",
    "* fix RAM accumulation issue\n",
    "\n",
    "## Remarks\n",
    "#### Benchmarking\n",
    "* need to ensure that results are same as if they were processed with native semantique alone\n",
    "* can't be achieved 100% due to among others...\n",
    "    * NA value handling -> maybe this should be integrated as mandatory part of recipes for TileHandler\n",
    "    * preview function -> will be parsed different as extent object (trim=True)\n",
    "\n",
    "#### Black stripes\n",
    "* problem of NA values during merge_spatial (rioxarray)\n",
    "    * uses per default NA value in first input DataArray\n",
    "    * if NA value not written, it will use rasterios default NA value (which is 0)\n",
    "* can be circumvented by explicitly making sure that NA value is set\n",
    "    * solution: udf - update_na\n",
    "\n",
    "#### Small polygons, Distributed features\n",
    "* polygons smaller than pixel size (spatial res) get omitted, points do not\n",
    "* can raise ValueError: zero-size array, which is also the case for usual non-tiled execution\n",
    "    * happen in case extent objects are defined for small objects\n",
    "    * e.g. in case of polygon_small for 02_sreduce.json but not for 01_treduce.json\n",
    "    * also due to preview with parse_extent, trim=True possible\n",
    "* small grids - a lot of unneeded tiles need to be created & omitted (create_spatial_grid takes time & memory)\n",
    "    * can be circumvented by just running precise_shp=True for large spatial chuncksizes\n",
    "\n",
    "#### Vrt as output\n",
    "* vrt covers way more than expected (400 x 400 still divided into 4 tiles) - not the minimal enclosing stuff is choosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import planetary_computer as pc\n",
    "import pystac\n",
    "import pytz\n",
    "import semantique as sq\n",
    "import shutil\n",
    "import urllib.request\n",
    "import warnings \n",
    "import zipfile\n",
    "\n",
    "from datetime import datetime\n",
    "from pystac import Catalog, get_stac_version\n",
    "from pystac.extensions.eo import EOExtension\n",
    "from pystac.extensions.label import LabelExtension\n",
    "from pystac_client import Client\n",
    "from semantique.processor.utils import parse_extent\n",
    "from shapely.geometry import box\n",
    "from pathlib import Path\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from gsemantique.data.search import Finder\n",
    "from gsemantique.process.scaling import TileHandler, TileHandlerParallel\n",
    "\n",
    "os.environ['USE_PYGEOS'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>collection</th>\n",
       "      <th>copyright</th>\n",
       "      <th>endpoint</th>\n",
       "      <th>info</th>\n",
       "      <th>layout_bands</th>\n",
       "      <th>layout_file</th>\n",
       "      <th>layout_keys</th>\n",
       "      <th>provider</th>\n",
       "      <th>spatial_extent</th>\n",
       "      <th>src</th>\n",
       "      <th>temporal_extent</th>\n",
       "      <th>temporality</th>\n",
       "      <th>n_bands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAR</td>\n",
       "      <td>sentinel-1-rtc</td>\n",
       "      <td>CC BY 4.0</td>\n",
       "      <td>https://planetarycomputer.microsoft.com/api/st...</td>\n",
       "      <td>Sentinel-1 represent radar imaging (SAR) satel...</td>\n",
       "      <td>{'s1_amp_vv': {'name': 'vv', 'description': 'G...</td>\n",
       "      <td>c:\\users\\felix\\repositories\\gsemantique\\gseman...</td>\n",
       "      <td>[(Planet, reflectance, s1_amp_vv), (Planet, re...</td>\n",
       "      <td>Planet</td>\n",
       "      <td>[[-180, -90, 180, 90]]</td>\n",
       "      <td>https://planetarycomputer.microsoft.com/datase...</td>\n",
       "      <td>[[2014-10-10 00:28:21+00:00, None]]</td>\n",
       "      <td>s</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>multispectral</td>\n",
       "      <td>sentinel-2-l2a</td>\n",
       "      <td>Copernicus Sentinel Data Terms</td>\n",
       "      <td>https://planetarycomputer.microsoft.com/api/st...</td>\n",
       "      <td>The Sentinel-2 program provides global imagery...</td>\n",
       "      <td>{'s2_band01': {'name': 'B01', 'description': '...</td>\n",
       "      <td>c:\\users\\felix\\repositories\\gsemantique\\gseman...</td>\n",
       "      <td>[(Planet, reflectance, s2_band01), (Planet, re...</td>\n",
       "      <td>Planet</td>\n",
       "      <td>[[-180, -90, 180, 90]]</td>\n",
       "      <td>https://planetarycomputer.microsoft.com/datase...</td>\n",
       "      <td>[[2015-06-27 10:25:31+00:00, None]]</td>\n",
       "      <td>s</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>multispectral</td>\n",
       "      <td>landsat-c2-l2</td>\n",
       "      <td>Public Domain (https://www.usgs.gov/emergency-...</td>\n",
       "      <td>https://planetarycomputer.microsoft.com/api/st...</td>\n",
       "      <td>Landsat Collection 2 Level-2 Science Products,...</td>\n",
       "      <td>{'lndst_coastal': {'name': 'coastal', 'descrip...</td>\n",
       "      <td>c:\\users\\felix\\repositories\\gsemantique\\gseman...</td>\n",
       "      <td>[(Planet, reflectance, lndst_coastal), (Planet...</td>\n",
       "      <td>Planet</td>\n",
       "      <td>[[-180.0, -90.0, 180.0, 90.0]]</td>\n",
       "      <td>https://planetarycomputer.microsoft.com/datase...</td>\n",
       "      <td>[[1982-08-22 00:00:00+00:00, None]]</td>\n",
       "      <td>s</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>landcover</td>\n",
       "      <td>esa-worldcover</td>\n",
       "      <td>Creative Commons Attribution 4.0 International...</td>\n",
       "      <td>https://planetarycomputer.microsoft.com/api/st...</td>\n",
       "      <td>The European Space Agency (ESA) WorldCover pro...</td>\n",
       "      <td>{'esa_lc': {'name': 'map', 'description': 'ESA...</td>\n",
       "      <td>c:\\users\\felix\\repositories\\gsemantique\\gseman...</td>\n",
       "      <td>[(Planet, classification, esa_lc)]</td>\n",
       "      <td>Planet</td>\n",
       "      <td>[[-180.0, -60.0, 180.0, 83.0]]</td>\n",
       "      <td>https://planetarycomputer.microsoft.com/datase...</td>\n",
       "      <td>[[2020-01-01 00:00:00+00:00, 2021-12-31 23:59:...</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>landcover</td>\n",
       "      <td>io-lulc-annual-v02</td>\n",
       "      <td>Creative Commons BY-4.0</td>\n",
       "      <td>https://planetarycomputer.microsoft.com/api/st...</td>\n",
       "      <td>Time series of annual global maps of land use ...</td>\n",
       "      <td>{'impact_lc': {'name': 'data', 'description': ...</td>\n",
       "      <td>c:\\users\\felix\\repositories\\gsemantique\\gseman...</td>\n",
       "      <td>[(Planet, classification, impact_lc)]</td>\n",
       "      <td>Planet</td>\n",
       "      <td>[[-180, -90, 180, 90]]</td>\n",
       "      <td>https://planetarycomputer.microsoft.com/datase...</td>\n",
       "      <td>[[2017-01-01 00:00:00+00:00, 2024-01-01 00:00:...</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DEM</td>\n",
       "      <td>nasadem</td>\n",
       "      <td>Public Domain (https://lpdaac.usgs.gov/data/da...</td>\n",
       "      <td>https://planetarycomputer.microsoft.com/api/st...</td>\n",
       "      <td>NASADEM provides global topographic data at 1 ...</td>\n",
       "      <td>{'dem': {'name': 'elevation', 'description': '...</td>\n",
       "      <td>c:\\users\\felix\\repositories\\gsemantique\\gseman...</td>\n",
       "      <td>[(Planet, topography, dem)]</td>\n",
       "      <td>Planet</td>\n",
       "      <td>[[-179.0, -56.0, 179.0, 61.0]]</td>\n",
       "      <td>https://planetarycomputer.microsoft.com/datase...</td>\n",
       "      <td>[[2000-02-20 00:00:00+00:00, 2000-02-20 00:00:...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DSM</td>\n",
       "      <td>cop-dem-glo-30</td>\n",
       "      <td>None</td>\n",
       "      <td>https://planetarycomputer.microsoft.com/api/st...</td>\n",
       "      <td>The Copernicus DEM is a digital surface model ...</td>\n",
       "      <td>{'dsm': {'name': 'data', 'description': 'Digit...</td>\n",
       "      <td>c:\\users\\felix\\repositories\\gsemantique\\gseman...</td>\n",
       "      <td>[(Planet, topography, dsm)]</td>\n",
       "      <td>Planet</td>\n",
       "      <td>[[-180, -90, 180, 90]]</td>\n",
       "      <td>https://planetarycomputer.microsoft.com/datase...</td>\n",
       "      <td>[[2021-04-22 00:00:00+00:00, 2021-04-22 00:00:...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fire detection</td>\n",
       "      <td>modis-64A1-061</td>\n",
       "      <td>None</td>\n",
       "      <td>https://planetarycomputer.microsoft.com/api/st...</td>\n",
       "      <td>The Terra and Aqua combined MCD64A1 Version 6....</td>\n",
       "      <td>{'m_burn_date': {'name': 'Burn_Date', 'descrip...</td>\n",
       "      <td>c:\\users\\felix\\repositories\\gsemantique\\gseman...</td>\n",
       "      <td>[(Planet, burned_mapping, m_burn_date), (Plane...</td>\n",
       "      <td>Planet</td>\n",
       "      <td>[[-180, -90, 180, 90]]</td>\n",
       "      <td>https://planetarycomputer.microsoft.com/datase...</td>\n",
       "      <td>[[2000-11-01 00:00:00+00:00, None]]</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fire detection</td>\n",
       "      <td>modis-14A2-061</td>\n",
       "      <td>None</td>\n",
       "      <td>https://planetarycomputer.microsoft.com/api/st...</td>\n",
       "      <td>The Moderate Resolution Imaging Spectroradiome...</td>\n",
       "      <td>{'w_burn_qa': {'name': 'QA', 'description': 'P...</td>\n",
       "      <td>c:\\users\\felix\\repositories\\gsemantique\\gseman...</td>\n",
       "      <td>[(Planet, burned_mapping, w_burn_qa), (Planet,...</td>\n",
       "      <td>Planet</td>\n",
       "      <td>[[-180, -90, 180, 90]]</td>\n",
       "      <td>https://planetarycomputer.microsoft.com/datase...</td>\n",
       "      <td>[[2000-02-18 00:00:00+00:00, None]]</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hydrogeography</td>\n",
       "      <td>jrc-gsw</td>\n",
       "      <td>Copernicus Open Access Policy</td>\n",
       "      <td>https://planetarycomputer.microsoft.com/api/st...</td>\n",
       "      <td>Global surface water products from the Europea...</td>\n",
       "      <td>{'change': {'name': 'change', 'description': '...</td>\n",
       "      <td>c:\\users\\felix\\repositories\\gsemantique\\gseman...</td>\n",
       "      <td>[(Planet, hydrogeography, change), (Planet, hy...</td>\n",
       "      <td>Planet</td>\n",
       "      <td>[[-180.0, -56.0, 180.0, 78.0]]</td>\n",
       "      <td>https://planetarycomputer.microsoft.com/datase...</td>\n",
       "      <td>[[1984-03-01 00:00:00+00:00, 2020-12-31 11:59:...</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>multispectral</td>\n",
       "      <td>sentinel-2-l2a</td>\n",
       "      <td>None</td>\n",
       "      <td>https://earth-search.aws.element84.com/v1</td>\n",
       "      <td>Sentinel-2 mission is a land monitoring conste...</td>\n",
       "      <td>{'s2_band01': {'name': 'coastal', 'description...</td>\n",
       "      <td>c:\\users\\felix\\repositories\\gsemantique\\gseman...</td>\n",
       "      <td>[(Element84, reflectance, s2_band01), (Element...</td>\n",
       "      <td>Element84</td>\n",
       "      <td>[[-180, -90, 180, 90]]</td>\n",
       "      <td>https://registry.opendata.aws/sentinel-2-l2a-c...</td>\n",
       "      <td>[[2015-06-27 10:25:31.456000+00:00, None]]</td>\n",
       "      <td>s</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SAR</td>\n",
       "      <td>sentinel-1-global-coherence</td>\n",
       "      <td>Creative Commons Zero (CC0) 1.0 Universal License</td>\n",
       "      <td>https://stac.asf.alaska.edu</td>\n",
       "      <td>Global C-band Synthetic Aperture Radar (SAR) i...</td>\n",
       "      <td>{'s1_coh6_vv': {'name': 'data', 'description':...</td>\n",
       "      <td>c:\\users\\felix\\repositories\\gsemantique\\gseman...</td>\n",
       "      <td>[(ASF, coherence, s1_coh6_vv), (ASF, coherence...</td>\n",
       "      <td>ASF</td>\n",
       "      <td>[[-180.0, -90.0, 180.0, 90.0]]</td>\n",
       "      <td>https://registry.opendata.aws/ebd-sentinel-1-g...</td>\n",
       "      <td>[[2019-12-01 00:00:00+00:00, 2020-11-30 00:00:...</td>\n",
       "      <td>3M</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hydrogeography</td>\n",
       "      <td>glo-30-hand</td>\n",
       "      <td>Creative Commons Attribution 4.0</td>\n",
       "      <td>https://stac.asf.alaska.edu</td>\n",
       "      <td>Height Above Nearest Drainage (HAND) is a terr...</td>\n",
       "      <td>{'hand': {'name': 'data', 'description': 'Heig...</td>\n",
       "      <td>c:\\users\\felix\\repositories\\gsemantique\\gseman...</td>\n",
       "      <td>[(ASF, hydrogeography, hand)]</td>\n",
       "      <td>ASF</td>\n",
       "      <td>[[-180.0, -90.0, 180.0, 90.0]]</td>\n",
       "      <td>https://registry.opendata.aws/glo-30-hand/</td>\n",
       "      <td>[[2010-12-01 00:00:00+00:00, 2015-02-01 00:00:...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          category                   collection  \\\n",
       "0              SAR               sentinel-1-rtc   \n",
       "1    multispectral               sentinel-2-l2a   \n",
       "2    multispectral                landsat-c2-l2   \n",
       "3        landcover               esa-worldcover   \n",
       "4        landcover           io-lulc-annual-v02   \n",
       "5              DEM                      nasadem   \n",
       "6              DSM               cop-dem-glo-30   \n",
       "7   fire detection               modis-64A1-061   \n",
       "8   fire detection               modis-14A2-061   \n",
       "9   hydrogeography                      jrc-gsw   \n",
       "10   multispectral               sentinel-2-l2a   \n",
       "11             SAR  sentinel-1-global-coherence   \n",
       "12  hydrogeography                  glo-30-hand   \n",
       "\n",
       "                                            copyright  \\\n",
       "0                                           CC BY 4.0   \n",
       "1                      Copernicus Sentinel Data Terms   \n",
       "2   Public Domain (https://www.usgs.gov/emergency-...   \n",
       "3   Creative Commons Attribution 4.0 International...   \n",
       "4                             Creative Commons BY-4.0   \n",
       "5   Public Domain (https://lpdaac.usgs.gov/data/da...   \n",
       "6                                                None   \n",
       "7                                                None   \n",
       "8                                                None   \n",
       "9                       Copernicus Open Access Policy   \n",
       "10                                               None   \n",
       "11  Creative Commons Zero (CC0) 1.0 Universal License   \n",
       "12                   Creative Commons Attribution 4.0   \n",
       "\n",
       "                                             endpoint  \\\n",
       "0   https://planetarycomputer.microsoft.com/api/st...   \n",
       "1   https://planetarycomputer.microsoft.com/api/st...   \n",
       "2   https://planetarycomputer.microsoft.com/api/st...   \n",
       "3   https://planetarycomputer.microsoft.com/api/st...   \n",
       "4   https://planetarycomputer.microsoft.com/api/st...   \n",
       "5   https://planetarycomputer.microsoft.com/api/st...   \n",
       "6   https://planetarycomputer.microsoft.com/api/st...   \n",
       "7   https://planetarycomputer.microsoft.com/api/st...   \n",
       "8   https://planetarycomputer.microsoft.com/api/st...   \n",
       "9   https://planetarycomputer.microsoft.com/api/st...   \n",
       "10          https://earth-search.aws.element84.com/v1   \n",
       "11                        https://stac.asf.alaska.edu   \n",
       "12                        https://stac.asf.alaska.edu   \n",
       "\n",
       "                                                 info  \\\n",
       "0   Sentinel-1 represent radar imaging (SAR) satel...   \n",
       "1   The Sentinel-2 program provides global imagery...   \n",
       "2   Landsat Collection 2 Level-2 Science Products,...   \n",
       "3   The European Space Agency (ESA) WorldCover pro...   \n",
       "4   Time series of annual global maps of land use ...   \n",
       "5   NASADEM provides global topographic data at 1 ...   \n",
       "6   The Copernicus DEM is a digital surface model ...   \n",
       "7   The Terra and Aqua combined MCD64A1 Version 6....   \n",
       "8   The Moderate Resolution Imaging Spectroradiome...   \n",
       "9   Global surface water products from the Europea...   \n",
       "10  Sentinel-2 mission is a land monitoring conste...   \n",
       "11  Global C-band Synthetic Aperture Radar (SAR) i...   \n",
       "12  Height Above Nearest Drainage (HAND) is a terr...   \n",
       "\n",
       "                                         layout_bands  \\\n",
       "0   {'s1_amp_vv': {'name': 'vv', 'description': 'G...   \n",
       "1   {'s2_band01': {'name': 'B01', 'description': '...   \n",
       "2   {'lndst_coastal': {'name': 'coastal', 'descrip...   \n",
       "3   {'esa_lc': {'name': 'map', 'description': 'ESA...   \n",
       "4   {'impact_lc': {'name': 'data', 'description': ...   \n",
       "5   {'dem': {'name': 'elevation', 'description': '...   \n",
       "6   {'dsm': {'name': 'data', 'description': 'Digit...   \n",
       "7   {'m_burn_date': {'name': 'Burn_Date', 'descrip...   \n",
       "8   {'w_burn_qa': {'name': 'QA', 'description': 'P...   \n",
       "9   {'change': {'name': 'change', 'description': '...   \n",
       "10  {'s2_band01': {'name': 'coastal', 'description...   \n",
       "11  {'s1_coh6_vv': {'name': 'data', 'description':...   \n",
       "12  {'hand': {'name': 'data', 'description': 'Heig...   \n",
       "\n",
       "                                          layout_file  \\\n",
       "0   c:\\users\\felix\\repositories\\gsemantique\\gseman...   \n",
       "1   c:\\users\\felix\\repositories\\gsemantique\\gseman...   \n",
       "2   c:\\users\\felix\\repositories\\gsemantique\\gseman...   \n",
       "3   c:\\users\\felix\\repositories\\gsemantique\\gseman...   \n",
       "4   c:\\users\\felix\\repositories\\gsemantique\\gseman...   \n",
       "5   c:\\users\\felix\\repositories\\gsemantique\\gseman...   \n",
       "6   c:\\users\\felix\\repositories\\gsemantique\\gseman...   \n",
       "7   c:\\users\\felix\\repositories\\gsemantique\\gseman...   \n",
       "8   c:\\users\\felix\\repositories\\gsemantique\\gseman...   \n",
       "9   c:\\users\\felix\\repositories\\gsemantique\\gseman...   \n",
       "10  c:\\users\\felix\\repositories\\gsemantique\\gseman...   \n",
       "11  c:\\users\\felix\\repositories\\gsemantique\\gseman...   \n",
       "12  c:\\users\\felix\\repositories\\gsemantique\\gseman...   \n",
       "\n",
       "                                          layout_keys   provider  \\\n",
       "0   [(Planet, reflectance, s1_amp_vv), (Planet, re...     Planet   \n",
       "1   [(Planet, reflectance, s2_band01), (Planet, re...     Planet   \n",
       "2   [(Planet, reflectance, lndst_coastal), (Planet...     Planet   \n",
       "3                  [(Planet, classification, esa_lc)]     Planet   \n",
       "4               [(Planet, classification, impact_lc)]     Planet   \n",
       "5                         [(Planet, topography, dem)]     Planet   \n",
       "6                         [(Planet, topography, dsm)]     Planet   \n",
       "7   [(Planet, burned_mapping, m_burn_date), (Plane...     Planet   \n",
       "8   [(Planet, burned_mapping, w_burn_qa), (Planet,...     Planet   \n",
       "9   [(Planet, hydrogeography, change), (Planet, hy...     Planet   \n",
       "10  [(Element84, reflectance, s2_band01), (Element...  Element84   \n",
       "11  [(ASF, coherence, s1_coh6_vv), (ASF, coherence...        ASF   \n",
       "12                      [(ASF, hydrogeography, hand)]        ASF   \n",
       "\n",
       "                    spatial_extent  \\\n",
       "0           [[-180, -90, 180, 90]]   \n",
       "1           [[-180, -90, 180, 90]]   \n",
       "2   [[-180.0, -90.0, 180.0, 90.0]]   \n",
       "3   [[-180.0, -60.0, 180.0, 83.0]]   \n",
       "4           [[-180, -90, 180, 90]]   \n",
       "5   [[-179.0, -56.0, 179.0, 61.0]]   \n",
       "6           [[-180, -90, 180, 90]]   \n",
       "7           [[-180, -90, 180, 90]]   \n",
       "8           [[-180, -90, 180, 90]]   \n",
       "9   [[-180.0, -56.0, 180.0, 78.0]]   \n",
       "10          [[-180, -90, 180, 90]]   \n",
       "11  [[-180.0, -90.0, 180.0, 90.0]]   \n",
       "12  [[-180.0, -90.0, 180.0, 90.0]]   \n",
       "\n",
       "                                                  src  \\\n",
       "0   https://planetarycomputer.microsoft.com/datase...   \n",
       "1   https://planetarycomputer.microsoft.com/datase...   \n",
       "2   https://planetarycomputer.microsoft.com/datase...   \n",
       "3   https://planetarycomputer.microsoft.com/datase...   \n",
       "4   https://planetarycomputer.microsoft.com/datase...   \n",
       "5   https://planetarycomputer.microsoft.com/datase...   \n",
       "6   https://planetarycomputer.microsoft.com/datase...   \n",
       "7   https://planetarycomputer.microsoft.com/datase...   \n",
       "8   https://planetarycomputer.microsoft.com/datase...   \n",
       "9   https://planetarycomputer.microsoft.com/datase...   \n",
       "10  https://registry.opendata.aws/sentinel-2-l2a-c...   \n",
       "11  https://registry.opendata.aws/ebd-sentinel-1-g...   \n",
       "12         https://registry.opendata.aws/glo-30-hand/   \n",
       "\n",
       "                                      temporal_extent temporality  n_bands  \n",
       "0                 [[2014-10-10 00:28:21+00:00, None]]           s        4  \n",
       "1                 [[2015-06-27 10:25:31+00:00, None]]           s       13  \n",
       "2                 [[1982-08-22 00:00:00+00:00, None]]           s       10  \n",
       "3   [[2020-01-01 00:00:00+00:00, 2021-12-31 23:59:...           Y        1  \n",
       "4   [[2017-01-01 00:00:00+00:00, 2024-01-01 00:00:...           Y        1  \n",
       "5   [[2000-02-20 00:00:00+00:00, 2000-02-20 00:00:...        None        1  \n",
       "6   [[2021-04-22 00:00:00+00:00, 2021-04-22 00:00:...        None        1  \n",
       "7                 [[2000-11-01 00:00:00+00:00, None]]           M        3  \n",
       "8                 [[2000-02-18 00:00:00+00:00, None]]           D        2  \n",
       "9   [[1984-03-01 00:00:00+00:00, 2020-12-31 11:59:...        None        4  \n",
       "10         [[2015-06-27 10:25:31.456000+00:00, None]]           s       13  \n",
       "11  [[2019-12-01 00:00:00+00:00, 2020-11-30 00:00:...          3M       17  \n",
       "12  [[2010-12-01 00:00:00+00:00, 2015-02-01 00:00:...        None        1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gsemantique.data.datasets import *\n",
    "ds_catalog = DatasetCatalog()\n",
    "ds_catalog.load()\n",
    "ds_catalog.parse_as_table(keys=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test both TileHandler and TileHanderParallel\n",
    "# disable reauth for tests\n",
    "\n",
    "# set up parameters to be assessed\n",
    "recipes = [x.as_posix() for x in Path(\"recipes\").rglob(\"*.json\")]\n",
    "t_intervals = [[\"2017-06-01\", \"2017-07-01\"], [\"2017-01-01\", \"2017-07-01\"]]\n",
    "aoi_files = [x.as_posix() for x in Path(\"aois\").rglob(\"*.geojson\")]\n",
    "aoi_processors = [\"bbox\", \"shapes\"] \n",
    "tile_handlers = [\"single\", \"parallel\"] \n",
    "\n",
    "# create test recipe\n",
    "# always recommended to use change_dtypes to reduce size of outputs\n",
    "# at least float32 can be used in almost all cases (instead of float64)\n",
    "# also tracking of no data values allowed this way\n",
    "\n",
    "def update_na(obj, track_types = True, na_value=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Updates NA values by...\n",
    "        * converting existing NA values to specified ones\n",
    "        * persisting the NA value as part of the rio metadata\n",
    "\n",
    "    Note that it doesn't turn existing non-NA values into NA values. \n",
    "    For this functionality see the verb `assign`.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import semantique as sq\n",
    "    newobj = obj.copy(deep = True)\n",
    "    na_value = eval(na_value) if isinstance(na_value, str) else na_value\n",
    "    if newobj.rio.nodata is None:\n",
    "        nodata = np.NaN if newobj.dtype.kind == \"f\" else None\n",
    "        if na_value is not None:\n",
    "            if nodata is np.NaN:\n",
    "                newobj.values = np.where(np.isnan(newobj.values), na_value, newobj.values)\n",
    "            else:\n",
    "                newobj.values = np.where(newobj.values == nodata, na_value, newobj.values)\n",
    "        else:\n",
    "            na_value = nodata\n",
    "        newobj = newobj.rio.write_nodata(na_value)\n",
    "    else:\n",
    "        if na_value is not None:\n",
    "            nodata = newobj.rio.nodata\n",
    "            if nodata is np.NaN:\n",
    "                newobj.values = np.where(np.isnan(newobj.values), na_value, newobj.values)\n",
    "            else:\n",
    "                newobj.values = np.where(newobj.values == nodata, na_value, newobj.values)\n",
    "            newobj = newobj.rio.write_nodata(na_value)\n",
    "    return newobj\n",
    "\n",
    "def change_dtype(obj, track_types = True, dtype=\"float32\", na_value=None, **kwargs):\n",
    "    import semantique as sq\n",
    "    # convert dtype\n",
    "    newobj = obj.copy(deep = True)\n",
    "    newobj.values = newobj.astype(dtype)\n",
    "    # track value types\n",
    "    if track_types:\n",
    "        newobj.sq.value_type = sq.processor.types.get_value_type(newobj)\n",
    "    return newobj\n",
    "    \n",
    "class Tester:\n",
    "    def __init__(\n",
    "        self, \n",
    "        recipe, \n",
    "        aoi_file, \n",
    "        t_interval = [\"2017-06-01\", \"2017-07-01\"], \n",
    "        tile_handler = \"single\", \n",
    "        merge_mode = \"merged\",\n",
    "        out_dir = False,\n",
    "        res = 100,\n",
    "        epsg = 3857\n",
    "    ):\n",
    "        self.recipe = recipe \n",
    "        self.t_interval = t_interval\n",
    "        self.aoi_file = aoi_file\n",
    "        self.tile_handler = tile_handler\n",
    "        self.merge_mode = merge_mode\n",
    "        self.out_dir = out_dir\n",
    "        self.res = res\n",
    "        self.epsg = epsg\n",
    "        # parse space\n",
    "        self.gdf = gpd.read_file(self.aoi_file).to_crs(4326)\n",
    "        self.aoi = box(*self.gdf.total_bounds)\n",
    "        self.space = sq.SpatialExtent(self.gdf)\n",
    "        # execute workflow\n",
    "        self._find_data()\n",
    "        self._create_context()\n",
    "        self._run_model()\n",
    "\n",
    "    def _find_data(self):\n",
    "        fdr = Finder(\n",
    "            self.t_interval[0], \n",
    "            self.t_interval[1], \n",
    "            self.aoi, \n",
    "            \"Planet\", \n",
    "            \"landsat-c2-l2\", \n",
    "            (\"Planet\", \"reflectance\", \"lndst_qa\")\n",
    "        )\n",
    "        fdr.retrieve_params()\n",
    "        fdr.retrieve_metadata()\n",
    "        fdr.postprocess_metadata()\n",
    "        self.fdr = fdr\n",
    "\n",
    "    def _create_context(self):\n",
    "        # init datacube\n",
    "        with open(self.fdr.params_search[\"lfile\"], \"r\") as file:\n",
    "            dc = sq.datacube.STACCube(\n",
    "                json.load(file), \n",
    "                src=self.fdr.item_coll,\n",
    "                group_by_solar_day=True,\n",
    "                dask_params=None,\n",
    "            )\n",
    "        # define spatio-temporal context vars\n",
    "        time = sq.TemporalExtent(\n",
    "            pd.Timestamp(self.fdr.params_search[\"t_start\"]), \n",
    "            pd.Timestamp(self.fdr.params_search[\"t_end\"])\n",
    "        )\n",
    "        space = sq.SpatialExtent(self.gdf)\n",
    "        # if self.aoi_processor == \"bbox\":\n",
    "        #     space = sq.SpatialExtent(\n",
    "        #         gpd.GeoDataFrame(\n",
    "        #             geometry=[box(*self.gdf.to_crs(self.epsg).total_bounds)], \n",
    "        #             crs=self.epsg\n",
    "        #             )\n",
    "        #         )\n",
    "        # load mapping\n",
    "        with open(\"mapping.json\", \"r\") as file:\n",
    "            rules = json.load(file)\n",
    "        mapping = sq.mapping.Semantique(rules)\n",
    "        # compose to context dict\n",
    "        context = {\n",
    "            \"datacube\": dc,\n",
    "            \"mapping\": mapping,\n",
    "            \"space\": space,\n",
    "            \"time\": time,\n",
    "            \"crs\": self.epsg,\n",
    "            \"tz\": \"UTC\",\n",
    "            \"spatial_resolution\": [-self.res, self.res],\n",
    "            \"caching\": True,\n",
    "            \"track_types\": False,\n",
    "        }\n",
    "        context = deepcopy(context)\n",
    "        context[\"custom_verbs\"] = {\"change_dtype\": change_dtype, \"update_na\": update_na}\n",
    "        self.context = context\n",
    "\n",
    "    def _run_model(self):\n",
    "        if self.out_dir:\n",
    "            # define output directory\n",
    "            out_dir = os.path.splitext(os.path.split(os.path.normpath(self.recipe))[-1])[0]\n",
    "            out_dir = f\"{datetime.now().strftime('%Y%m%d_%H%M%S')}_{out_dir}\"\n",
    "            out_dir = f\"results/{out_dir}\"\n",
    "            if os.path.exists(out_dir):\n",
    "                shutil.rmtree(out_dir)\n",
    "        else:\n",
    "            out_dir = None\n",
    "        \n",
    "        # load recipe\n",
    "        with open(self.recipe, \"r\") as file:\n",
    "            recipe = json.load(file)\n",
    "        recipe = sq.QueryRecipe(recipe)\n",
    "\n",
    "        # just for debugging purposes\n",
    "        if self.tile_handler == \"None\":\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\", UserWarning)\n",
    "                context = self.context\n",
    "                context[\"preview\"] = False\n",
    "                context[\"caching\"] = False\n",
    "                self.response = recipe.execute(**context)\n",
    "\n",
    "        if self.tile_handler == \"single\":\n",
    "            self.th = TileHandler(\n",
    "                recipe, \n",
    "                chunksize_s=256,\n",
    "                chunksize_t=\"2W\",\n",
    "                merge_mode=self.merge_mode, \n",
    "                out_dir=out_dir,\n",
    "                reauth=False, \n",
    "                verbose=True, \n",
    "                **self.context\n",
    "            )\n",
    "            self.th.execute()\n",
    "            # if self.merge_mode==\"single\":\n",
    "            #     self.response = self.th.joint_res\n",
    "\n",
    "        elif self.tile_handler == \"parallel\":\n",
    "            self.th = TileHandlerParallel(\n",
    "                recipe, \n",
    "                chunksize_s=128, \n",
    "                merge_mode=self.merge_mode, \n",
    "                out_dir=out_dir, \n",
    "                reauth=False, \n",
    "                verbose=True, \n",
    "                n_procs=os.cpu_count(), \n",
    "                **self.context\n",
    "            )\n",
    "            self.th.execute()\n",
    "            if self.merge_mode==\"single\":\n",
    "                self.response = self.th.joint_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remaining\n",
    "# MultiProcessorTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 26 datasets\n",
      "The following numbers are rough estimations depending on the chosen strategy for merging the individual tile results. If merge='merged' is choosen the total size indicates a lower bound for how much RAM is required since the individual tile results will be stored in RAM before merging.\n",
      "\n",
      "---------------------------------------\n",
      "General layer info\n",
      "---------------------------------------\n",
      "layer     : dtype     crs   res        \n",
      "---------------------------------------\n",
      "obs_count : float64   32634 [-100, 100]\n",
      "---------------------------------------\n",
      "\n",
      "------------------------------------------\n",
      "Scenario: 'merge' = None\n",
      "------------------------------------------\n",
      "layer     :  size     tile n    tile shape\n",
      "------------------------------------------\n",
      "obs_count : 0.00 Gb  4 tile(s)  (256, 256)\n",
      "------------------------------------------\n",
      "Total       0.00 Gb  4 tile(s)\n",
      "------------------------------------------\n",
      "\n",
      "------------------------------------------\n",
      "Scenario: 'merge' = vrt_*\n",
      "------------------------------------------\n",
      "layer     :  size     tile n    tile shape\n",
      "------------------------------------------\n",
      "obs_count : 0.00 Gb  4 tile(s)  (256, 256)\n",
      "------------------------------------------\n",
      "Total       0.00 Gb  4 tile(s)\n",
      "------------------------------------------\n",
      "\n",
      "------------------------------------------\n",
      "Scenario: 'merge' = merged\n",
      "------------------------------------------\n",
      "layer     :  size     tile n    tile shape\n",
      "------------------------------------------\n",
      "obs_count : 0.00 Gb  1 tile(s)  (233, 271)\n",
      "------------------------------------------\n",
      "Total       0.00 Gb  1 tile(s)\n",
      "------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 26 datasets\n",
      "The following numbers are rough estimations depending on the chosen strategy for merging the individual tile results. If merge='merged' is choosen the total size indicates a lower bound for how much RAM is required since the individual tile results will be stored in RAM before merging.\n",
      "\n",
      "---------------------------------------\n",
      "General layer info\n",
      "---------------------------------------\n",
      "layer     : dtype     crs   res        \n",
      "---------------------------------------\n",
      "obs_count : float64   32634 [-100, 100]\n",
      "---------------------------------------\n",
      "\n",
      "------------------------------------------\n",
      "Scenario: 'merge' = None\n",
      "------------------------------------------\n",
      "layer     :  size     tile n    tile shape\n",
      "------------------------------------------\n",
      "obs_count : 0.00 Gb  4 tile(s)  (256, 256)\n",
      "------------------------------------------\n",
      "Total       0.00 Gb  4 tile(s)\n",
      "------------------------------------------\n",
      "\n",
      "------------------------------------------\n",
      "Scenario: 'merge' = vrt_*\n",
      "------------------------------------------\n",
      "layer     :  size     tile n    tile shape\n",
      "------------------------------------------\n",
      "obs_count : 0.00 Gb  4 tile(s)  (256, 256)\n",
      "------------------------------------------\n",
      "Total       0.00 Gb  4 tile(s)\n",
      "------------------------------------------\n",
      "\n",
      "------------------------------------------\n",
      "Scenario: 'merge' = merged\n",
      "------------------------------------------\n",
      "layer     :  size     tile n    tile shape\n",
      "------------------------------------------\n",
      "obs_count : 0.00 Gb  1 tile(s)  (233, 271)\n",
      "------------------------------------------\n",
      "Total       0.00 Gb  1 tile(s)\n",
      "------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 26 datasets\n",
      "The following numbers are rough estimations depending on the chosen strategy for merging the individual tile results. If merge='merged' is choosen the total size indicates a lower bound for how much RAM is required since the individual tile results will be stored in RAM before merging.\n",
      "\n",
      "---------------------------------------\n",
      "General layer info\n",
      "---------------------------------------\n",
      "layer     : dtype     crs   res        \n",
      "---------------------------------------\n",
      "obs_count : float64   32634 [-100, 100]\n",
      "---------------------------------------\n",
      "\n",
      "------------------------------------------\n",
      "Scenario: 'merge' = None\n",
      "------------------------------------------\n",
      "layer     :  size     tile n    tile shape\n",
      "------------------------------------------\n",
      "obs_count : 0.00 Gb  4 tile(s)  (256, 256)\n",
      "------------------------------------------\n",
      "Total       0.00 Gb  4 tile(s)\n",
      "------------------------------------------\n",
      "\n",
      "------------------------------------------\n",
      "Scenario: 'merge' = vrt_*\n",
      "------------------------------------------\n",
      "layer     :  size     tile n    tile shape\n",
      "------------------------------------------\n",
      "obs_count : 0.00 Gb  4 tile(s)  (256, 256)\n",
      "------------------------------------------\n",
      "Total       0.00 Gb  4 tile(s)\n",
      "------------------------------------------\n",
      "\n",
      "------------------------------------------\n",
      "Scenario: 'merge' = merged\n",
      "------------------------------------------\n",
      "layer     :  size     tile n    tile shape\n",
      "------------------------------------------\n",
      "obs_count : 0.00 Gb  1 tile(s)  (233, 271)\n",
      "------------------------------------------\n",
      "Total       0.00 Gb  1 tile(s)\n",
      "------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 14 datasets\n",
      "The following numbers are rough estimations depending on the chosen strategy for merging the individual tile results. If merge='merged' is choosen the total size indicates a lower bound for how much RAM is required since the individual tile results will be stored in RAM before merging.\n",
      "\n",
      "---------------------------------------\n",
      "General layer info\n",
      "---------------------------------------\n",
      "layer     : dtype     crs   res        \n",
      "---------------------------------------\n",
      "obs_count : float64   32754 [-100, 100]\n",
      "---------------------------------------\n",
      "\n",
      "------------------------------------------\n",
      "Scenario: 'merge' = None\n",
      "------------------------------------------\n",
      "layer     :  size     tile n    tile shape\n",
      "------------------------------------------\n",
      "obs_count : 0.00 Gb  5 tile(s)  (256, 256)\n",
      "------------------------------------------\n",
      "Total       0.00 Gb  5 tile(s)\n",
      "------------------------------------------\n",
      "\n",
      "------------------------------------------\n",
      "Scenario: 'merge' = vrt_*\n",
      "------------------------------------------\n",
      "layer     :  size     tile n    tile shape\n",
      "------------------------------------------\n",
      "obs_count : 0.00 Gb  5 tile(s)  (256, 256)\n",
      "------------------------------------------\n",
      "Total       0.00 Gb  5 tile(s)\n",
      "------------------------------------------\n",
      "\n",
      "------------------------------------------\n",
      "Scenario: 'merge' = merged\n",
      "------------------------------------------\n",
      "layer     :  size     tile n    tile shape\n",
      "------------------------------------------\n",
      "obs_count : 0.00 Gb  1 tile(s)  (363, 438)\n",
      "------------------------------------------\n",
      "Total       0.00 Gb  1 tile(s)\n",
      "------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 31 datasets\n",
      "The following numbers are rough estimations depending on the chosen strategy for merging the individual tile results. If merge='merged' is choosen the total size indicates a lower bound for how much RAM is required since the individual tile results will be stored in RAM before merging.\n",
      "\n",
      "---------------------------------------\n",
      "General layer info\n",
      "---------------------------------------\n",
      "layer     : dtype     crs   res        \n",
      "---------------------------------------\n",
      "obs_count : float64   32634 [-100, 100]\n",
      "---------------------------------------\n",
      "\n",
      "------------------------------------------\n",
      "Scenario: 'merge' = None\n",
      "------------------------------------------\n",
      "layer     :  size     tile n    tile shape\n",
      "------------------------------------------\n",
      "obs_count : 0.00 Gb  5 tile(s)  (256, 256)\n",
      "------------------------------------------\n",
      "Total       0.00 Gb  5 tile(s)\n",
      "------------------------------------------\n",
      "\n",
      "------------------------------------------\n",
      "Scenario: 'merge' = vrt_*\n",
      "------------------------------------------\n",
      "layer     :  size     tile n    tile shape\n",
      "------------------------------------------\n",
      "obs_count : 0.00 Gb  5 tile(s)  (256, 256)\n",
      "------------------------------------------\n",
      "Total       0.00 Gb  5 tile(s)\n",
      "------------------------------------------\n",
      "\n",
      "--------------------------------------------\n",
      "Scenario: 'merge' = merged\n",
      "--------------------------------------------\n",
      "layer     :  size     tile n     tile shape \n",
      "--------------------------------------------\n",
      "obs_count : 0.02 Gb  1 tile(s)  (1864, 1335)\n",
      "--------------------------------------------\n",
      "Total       0.02 Gb  1 tile(s)\n",
      "--------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 26 datasets\n",
      "The following numbers are rough estimations depending on the chosen strategy for merging the individual tile results. If merge='merged' is choosen the total size indicates a lower bound for how much RAM is required since the individual tile results will be stored in RAM before merging.\n",
      "\n",
      "-------------------------------------\n",
      "General layer info\n",
      "-------------------------------------\n",
      "layer     : dtype     crs   res      \n",
      "-------------------------------------\n",
      "obs_count : float64   32632 [-50, 50]\n",
      "-------------------------------------\n",
      "\n",
      "------------------------------------------\n",
      "Scenario: 'merge' = None\n",
      "------------------------------------------\n",
      "layer     :  size     tile n    tile shape\n",
      "------------------------------------------\n",
      "obs_count : 0.00 Gb  5 tile(s)  (256, 256)\n",
      "------------------------------------------\n",
      "Total       0.00 Gb  5 tile(s)\n",
      "------------------------------------------\n",
      "\n",
      "------------------------------------------\n",
      "Scenario: 'merge' = vrt_*\n",
      "------------------------------------------\n",
      "layer     :  size     tile n    tile shape\n",
      "------------------------------------------\n",
      "obs_count : 0.00 Gb  5 tile(s)  (256, 256)\n",
      "------------------------------------------\n",
      "Total       0.00 Gb  5 tile(s)\n",
      "------------------------------------------\n",
      "\n",
      "------------------------------------------\n",
      "Scenario: 'merge' = merged\n",
      "------------------------------------------\n",
      "layer     :  size     tile n    tile shape\n",
      "------------------------------------------\n",
      "obs_count : 0.00 Gb  1 tile(s)  (520, 499)\n",
      "------------------------------------------\n",
      "Total       0.00 Gb  1 tile(s)\n",
      "------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 26 datasets\n",
      "preview() is currently only implemented for spatial outputs. Unless you are processing very dense timeseries and/or processing many features it's save to assume that the size of your output is rather small, so don't worry about the memory space.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 26 datasets\n",
      "The following numbers are rough estimations depending on the chosen strategy for merging the individual tile results. If merge='merged' is choosen the total size indicates a lower bound for how much RAM is required since the individual tile results will be stored in RAM before merging.\n",
      "\n",
      "---------------------------------------\n",
      "General layer info\n",
      "---------------------------------------\n",
      "layer     : dtype     crs   res        \n",
      "---------------------------------------\n",
      "obs_count : float64   32634 [-100, 100]\n",
      "---------------------------------------\n",
      "\n",
      "---------------------------------------------\n",
      "Scenario: 'merge' = None\n",
      "---------------------------------------------\n",
      "layer     :  size     tile n     tile shape  \n",
      "---------------------------------------------\n",
      "obs_count : 0.00 Gb  4 tile(s)  (1, 256, 256)\n",
      "---------------------------------------------\n",
      "Total       0.00 Gb  4 tile(s)\n",
      "---------------------------------------------\n",
      "\n",
      "---------------------------------------------\n",
      "Scenario: 'merge' = vrt_*\n",
      "---------------------------------------------\n",
      "layer     :  size     tile n     tile shape  \n",
      "---------------------------------------------\n",
      "obs_count : 0.00 Gb  4 tile(s)  (1, 256, 256)\n",
      "---------------------------------------------\n",
      "Total       0.00 Gb  4 tile(s)\n",
      "---------------------------------------------\n",
      "\n",
      "---------------------------------------------\n",
      "Scenario: 'merge' = merged\n",
      "---------------------------------------------\n",
      "layer     :  size     tile n     tile shape  \n",
      "---------------------------------------------\n",
      "obs_count : 0.00 Gb  1 tile(s)  (1, 233, 271)\n",
      "---------------------------------------------\n",
      "Total       0.00 Gb  1 tile(s)\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 78 datasets\n",
      "The following numbers are rough estimations depending on the chosen strategy for merging the individual tile results. If merge='merged' is choosen the total size indicates a lower bound for how much RAM is required since the individual tile results will be stored in RAM before merging.\n",
      "\n",
      "---------------------------------------\n",
      "General layer info\n",
      "---------------------------------------\n",
      "layer     : dtype     crs   res        \n",
      "---------------------------------------\n",
      "obs_count : float64   32754 [-100, 100]\n",
      "---------------------------------------\n",
      "\n",
      "---------------------------------------------\n",
      "Scenario: 'merge' = None\n",
      "---------------------------------------------\n",
      "layer     :  size     tile n     tile shape  \n",
      "---------------------------------------------\n",
      "obs_count : 0.01 Gb  5 tile(s)  (6, 256, 256)\n",
      "---------------------------------------------\n",
      "Total       0.01 Gb  5 tile(s)\n",
      "---------------------------------------------\n",
      "\n",
      "---------------------------------------------\n",
      "Scenario: 'merge' = vrt_*\n",
      "---------------------------------------------\n",
      "layer     :  size     tile n     tile shape  \n",
      "---------------------------------------------\n",
      "obs_count : 0.02 Gb  5 tile(s)  (6, 256, 256)\n",
      "---------------------------------------------\n",
      "Total       0.02 Gb  5 tile(s)\n",
      "---------------------------------------------\n",
      "\n",
      "---------------------------------------------\n",
      "Scenario: 'merge' = merged\n",
      "---------------------------------------------\n",
      "layer     :  size     tile n     tile shape  \n",
      "---------------------------------------------\n",
      "obs_count : 0.01 Gb  1 tile(s)  (6, 363, 438)\n",
      "---------------------------------------------\n",
      "Total       0.01 Gb  1 tile(s)\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 26 datasets\n",
      "preview() is currently only implemented for spatial outputs. Unless you are processing very dense timeseries and/or processing many features it's save to assume that the size of your output is rather small, so don't worry about the memory space.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:02<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 78 datasets\n",
      "The following numbers are rough estimations depending on the chosen strategy for merging the individual tile results. If merge='merged' is choosen the total size indicates a lower bound for how much RAM is required since the individual tile results will be stored in RAM before merging.\n",
      "\n",
      "---------------------------------------\n",
      "General layer info\n",
      "---------------------------------------\n",
      "layer     : dtype     crs   res        \n",
      "---------------------------------------\n",
      "obs_count : float64   32754 [-100, 100]\n",
      "---------------------------------------\n",
      "\n",
      "---------------------------------------------\n",
      "Scenario: 'merge' = None\n",
      "---------------------------------------------\n",
      "layer     :  size     tile n     tile shape  \n",
      "---------------------------------------------\n",
      "obs_count : 0.01 Gb  5 tile(s)  (6, 256, 256)\n",
      "---------------------------------------------\n",
      "Total       0.01 Gb  5 tile(s)\n",
      "---------------------------------------------\n",
      "\n",
      "---------------------------------------------\n",
      "Scenario: 'merge' = vrt_*\n",
      "---------------------------------------------\n",
      "layer     :  size     tile n     tile shape  \n",
      "---------------------------------------------\n",
      "obs_count : 0.02 Gb  5 tile(s)  (6, 256, 256)\n",
      "---------------------------------------------\n",
      "Total       0.02 Gb  5 tile(s)\n",
      "---------------------------------------------\n",
      "\n",
      "---------------------------------------------\n",
      "Scenario: 'merge' = merged\n",
      "---------------------------------------------\n",
      "layer     :  size     tile n     tile shape  \n",
      "---------------------------------------------\n",
      "obs_count : 0.01 Gb  1 tile(s)  (6, 363, 438)\n",
      "---------------------------------------------\n",
      "Total       0.01 Gb  1 tile(s)\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 189 datasets\n",
      "The following numbers are rough estimations depending on the chosen strategy for merging the individual tile results. If merge='merged' is choosen the total size indicates a lower bound for how much RAM is required since the individual tile results will be stored in RAM before merging.\n",
      "\n",
      "---------------------------------------\n",
      "General layer info\n",
      "---------------------------------------\n",
      "layer     : dtype     crs   res        \n",
      "---------------------------------------\n",
      "obs_count : float64   32632 [-100, 100]\n",
      "---------------------------------------\n",
      "\n",
      "---------------------------------------------\n",
      "Scenario: 'merge' = None\n",
      "---------------------------------------------\n",
      "layer     :  size     tile n     tile shape  \n",
      "---------------------------------------------\n",
      "obs_count : 0.02 Gb  6 tile(s)  (6, 256, 256)\n",
      "---------------------------------------------\n",
      "Total       0.02 Gb  6 tile(s)\n",
      "---------------------------------------------\n",
      "\n",
      "---------------------------------------------\n",
      "Scenario: 'merge' = vrt_*\n",
      "---------------------------------------------\n",
      "layer     :  size     tile n     tile shape  \n",
      "---------------------------------------------\n",
      "obs_count : 0.03 Gb  6 tile(s)  (6, 256, 256)\n",
      "---------------------------------------------\n",
      "Total       0.03 Gb  6 tile(s)\n",
      "---------------------------------------------\n",
      "\n",
      "-----------------------------------------------\n",
      "Scenario: 'merge' = merged\n",
      "-----------------------------------------------\n",
      "layer     :  size     tile n      tile shape   \n",
      "-----------------------------------------------\n",
      "obs_count : 0.11 Gb  1 tile(s)  (6, 1971, 1226)\n",
      "-----------------------------------------------\n",
      "Total       0.11 Gb  1 tile(s)\n",
      "-----------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 26 datasets\n",
      "preview() is currently only implemented for spatial outputs. Unless you are processing very dense timeseries and/or processing many features it's save to assume that the size of your output is rather small, so don't worry about the memory space.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:02<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 14 datasets\n",
      "preview() is currently only implemented for spatial outputs. Unless you are processing very dense timeseries and/or processing many features it's save to assume that the size of your output is rather small, so don't worry about the memory space.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 26 datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\felix\\.virtualenvs\\gsemantique\\lib\\site-packages\\semantique\\processor\\reducers.py:97: RuntimeWarning: All-NaN slice encountered\n",
      "  return np.nanmedian(x, axis = axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following numbers are rough estimations depending on the chosen strategy for merging the individual tile results. If merge='merged' is choosen the total size indicates a lower bound for how much RAM is required since the individual tile results will be stored in RAM before merging.\n",
      "\n",
      "--------------------------------------\n",
      "General layer info\n",
      "--------------------------------------\n",
      "layer    : dtype     crs   res        \n",
      "--------------------------------------\n",
      "aoi_mask : float64   32634 [-100, 100]\n",
      "comp     : float32   32634 [-100, 100]\n",
      "--------------------------------------\n",
      "\n",
      "--------------------------------------------\n",
      "Scenario: 'merge' = None\n",
      "--------------------------------------------\n",
      "layer    :  size     tile n     tile shape  \n",
      "--------------------------------------------\n",
      "aoi_mask : 0.00 Gb  4 tile(s)     (256, 256)\n",
      "comp     : 0.00 Gb  4 tile(s)  (3, 256, 256)\n",
      "--------------------------------------------\n",
      "Total      0.00 Gb  8 tile(s)\n",
      "--------------------------------------------\n",
      "\n",
      "--------------------------------------------\n",
      "Scenario: 'merge' = vrt_*\n",
      "--------------------------------------------\n",
      "layer    :  size     tile n     tile shape  \n",
      "--------------------------------------------\n",
      "aoi_mask : 0.00 Gb  4 tile(s)     (256, 256)\n",
      "comp     : 0.00 Gb  4 tile(s)  (3, 256, 256)\n",
      "--------------------------------------------\n",
      "Total      0.00 Gb  8 tile(s)\n",
      "--------------------------------------------\n",
      "\n",
      "--------------------------------------------\n",
      "Scenario: 'merge' = merged\n",
      "--------------------------------------------\n",
      "layer    :  size     tile n     tile shape  \n",
      "--------------------------------------------\n",
      "aoi_mask : 0.00 Gb  1 tile(s)     (233, 271)\n",
      "comp     : 0.00 Gb  1 tile(s)  (3, 233, 271)\n",
      "--------------------------------------------\n",
      "Total      0.00 Gb  2 tile(s)\n",
      "--------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]c:\\Users\\felix\\.virtualenvs\\gsemantique\\lib\\site-packages\\semantique\\processor\\reducers.py:97: RuntimeWarning: All-NaN slice encountered\n",
      "  return np.nanmedian(x, axis = axis)\n",
      " 25%|██▌       | 1/4 [00:03<00:10,  3.42s/it]c:\\Users\\felix\\.virtualenvs\\gsemantique\\lib\\site-packages\\semantique\\processor\\reducers.py:97: RuntimeWarning: All-NaN slice encountered\n",
      "  return np.nanmedian(x, axis = axis)\n",
      " 50%|█████     | 2/4 [00:07<00:08,  4.09s/it]c:\\Users\\felix\\.virtualenvs\\gsemantique\\lib\\site-packages\\semantique\\processor\\reducers.py:97: RuntimeWarning: All-NaN slice encountered\n",
      "  return np.nanmedian(x, axis = axis)\n",
      " 75%|███████▌  | 3/4 [00:11<00:03,  3.76s/it]c:\\Users\\felix\\.virtualenvs\\gsemantique\\lib\\site-packages\\semantique\\processor\\reducers.py:97: RuntimeWarning: All-NaN slice encountered\n",
      "  return np.nanmedian(x, axis = axis)\n",
      "100%|██████████| 4/4 [00:12<00:00,  3.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 26 datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\felix\\.virtualenvs\\gsemantique\\lib\\site-packages\\semantique\\processor\\reducers.py:97: RuntimeWarning: All-NaN slice encountered\n",
      "  return np.nanmedian(x, axis = axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following numbers are rough estimations depending on the chosen strategy for merging the individual tile results. If merge='merged' is choosen the total size indicates a lower bound for how much RAM is required since the individual tile results will be stored in RAM before merging.\n",
      "\n",
      "--------------------------------------\n",
      "General layer info\n",
      "--------------------------------------\n",
      "layer    : dtype     crs   res        \n",
      "--------------------------------------\n",
      "aoi_mask : float64   32634 [-100, 100]\n",
      "comp     : float32   32634 [-100, 100]\n",
      "--------------------------------------\n",
      "\n",
      "--------------------------------------------\n",
      "Scenario: 'merge' = None\n",
      "--------------------------------------------\n",
      "layer    :  size     tile n     tile shape  \n",
      "--------------------------------------------\n",
      "aoi_mask : 0.00 Gb  4 tile(s)     (256, 256)\n",
      "comp     : 0.00 Gb  4 tile(s)  (3, 256, 256)\n",
      "--------------------------------------------\n",
      "Total      0.00 Gb  8 tile(s)\n",
      "--------------------------------------------\n",
      "\n",
      "--------------------------------------------\n",
      "Scenario: 'merge' = vrt_*\n",
      "--------------------------------------------\n",
      "layer    :  size     tile n     tile shape  \n",
      "--------------------------------------------\n",
      "aoi_mask : 0.00 Gb  4 tile(s)     (256, 256)\n",
      "comp     : 0.00 Gb  4 tile(s)  (3, 256, 256)\n",
      "--------------------------------------------\n",
      "Total      0.00 Gb  8 tile(s)\n",
      "--------------------------------------------\n",
      "\n",
      "--------------------------------------------\n",
      "Scenario: 'merge' = merged\n",
      "--------------------------------------------\n",
      "layer    :  size     tile n     tile shape  \n",
      "--------------------------------------------\n",
      "aoi_mask : 0.00 Gb  1 tile(s)     (233, 271)\n",
      "comp     : 0.00 Gb  1 tile(s)  (3, 233, 271)\n",
      "--------------------------------------------\n",
      "Total      0.00 Gb  2 tile(s)\n",
      "--------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]c:\\Users\\felix\\.virtualenvs\\gsemantique\\lib\\site-packages\\semantique\\processor\\reducers.py:97: RuntimeWarning: All-NaN slice encountered\n",
      "  return np.nanmedian(x, axis = axis)\n",
      " 25%|██▌       | 1/4 [00:03<00:11,  3.78s/it]c:\\Users\\felix\\.virtualenvs\\gsemantique\\lib\\site-packages\\semantique\\processor\\reducers.py:97: RuntimeWarning: All-NaN slice encountered\n",
      "  return np.nanmedian(x, axis = axis)\n",
      " 50%|█████     | 2/4 [00:07<00:08,  4.01s/it]c:\\Users\\felix\\.virtualenvs\\gsemantique\\lib\\site-packages\\semantique\\processor\\reducers.py:97: RuntimeWarning: All-NaN slice encountered\n",
      "  return np.nanmedian(x, axis = axis)\n",
      " 75%|███████▌  | 3/4 [00:11<00:03,  3.77s/it]c:\\Users\\felix\\.virtualenvs\\gsemantique\\lib\\site-packages\\semantique\\processor\\reducers.py:97: RuntimeWarning: All-NaN slice encountered\n",
      "  return np.nanmedian(x, axis = axis)\n",
      "100%|██████████| 4/4 [00:12<00:00,  3.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 26 datasets\n",
      "The following numbers are rough estimations depending on the chosen strategy for merging the individual tile results. If merge='merged' is choosen the total size indicates a lower bound for how much RAM is required since the individual tile results will be stored in RAM before merging.\n",
      "\n",
      "---------------------------------------\n",
      "General layer info\n",
      "---------------------------------------\n",
      "layer     : dtype     crs   res        \n",
      "---------------------------------------\n",
      "obs_count : int16     32634 [-100, 100]\n",
      "---------------------------------------\n",
      "\n",
      "------------------------------------------\n",
      "Scenario: 'merge' = None\n",
      "------------------------------------------\n",
      "layer     :  size     tile n    tile shape\n",
      "------------------------------------------\n",
      "obs_count : 0.00 Gb  4 tile(s)  (256, 256)\n",
      "------------------------------------------\n",
      "Total       0.00 Gb  4 tile(s)\n",
      "------------------------------------------\n",
      "\n",
      "------------------------------------------\n",
      "Scenario: 'merge' = vrt_*\n",
      "------------------------------------------\n",
      "layer     :  size     tile n    tile shape\n",
      "------------------------------------------\n",
      "obs_count : 0.00 Gb  4 tile(s)  (256, 256)\n",
      "------------------------------------------\n",
      "Total       0.00 Gb  4 tile(s)\n",
      "------------------------------------------\n",
      "\n",
      "------------------------------------------\n",
      "Scenario: 'merge' = merged\n",
      "------------------------------------------\n",
      "layer     :  size     tile n    tile shape\n",
      "------------------------------------------\n",
      "obs_count : 0.00 Gb  1 tile(s)  (233, 271)\n",
      "------------------------------------------\n",
      "Total       0.00 Gb  1 tile(s)\n",
      "------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:20<00:00,  5.17s/it]\n"
     ]
    }
   ],
   "source": [
    "# successful tests?\n",
    "tester = Tester( \n",
    "    recipe = 'recipes/01_treduce.json',\n",
    "    aoi_file = \"aois/polygon.geojson\",\n",
    "    t_interval = t_intervals[0],\n",
    "    tile_handler = \"single\", \n",
    "    merge_mode = \"merged\",\n",
    "    out_dir = True,\n",
    "    res = 100,\n",
    "    epsg = 32634\n",
    ")\n",
    "\n",
    "tester = Tester( \n",
    "    recipe = 'recipes/01_treduce.json',\n",
    "    aoi_file = \"aois/polygon.geojson\",\n",
    "    t_interval = t_intervals[0],\n",
    "    tile_handler = \"single\", \n",
    "    merge_mode = \"merged\",\n",
    "    out_dir = True,\n",
    "    res = 100,\n",
    "    epsg = 32634\n",
    ")\n",
    "\n",
    "tester = Tester( \n",
    "    recipe = 'recipes/01_treduce.json',\n",
    "    aoi_file = \"aois/polygon.geojson\",\n",
    "    t_interval = t_intervals[0],\n",
    "    tile_handler = \"single\", \n",
    "    merge_mode = \"vrt_shapes\",\n",
    "    out_dir = True,\n",
    "    res = 100,\n",
    "    epsg = 32634\n",
    ")\n",
    "\n",
    "# works (omits small polygon)\n",
    "tester = Tester( \n",
    "    recipe = 'recipes/01_treduce.json',\n",
    "    aoi_file = \"aois/multipolygon.geojson\",\n",
    "    t_interval = t_intervals[0],\n",
    "    tile_handler = \"single\", \n",
    "    merge_mode = \"vrt_shapes\",\n",
    "    out_dir = True,\n",
    "    res = 100,\n",
    "    epsg = 32754\n",
    ")\n",
    "\n",
    "tester = Tester( \n",
    "    recipe = 'recipes/01_treduce.json',\n",
    "    aoi_file = \"aois/multipoint.geojson\",\n",
    "    t_interval = t_intervals[0],\n",
    "    tile_handler = \"single\", \n",
    "    merge_mode = \"vrt_shapes\",\n",
    "    out_dir = True,\n",
    "    res = 100,\n",
    "    epsg = 32634\n",
    ")\n",
    "\n",
    "\n",
    "tester = Tester( \n",
    "    recipe = 'recipes/01_treduce.json',\n",
    "    aoi_file = \"aois/polygon.geojson\",\n",
    "    t_interval = t_intervals[0],\n",
    "    tile_handler = \"single\", \n",
    "    merge_mode = \"merged\",\n",
    "    out_dir = True,\n",
    "    res = 50,\n",
    "    epsg = 32632\n",
    ")\n",
    "\n",
    "tester = Tester( \n",
    "    recipe = 'recipes/02_sreduce.json',\n",
    "    aoi_file = \"aois/polygon.geojson\",\n",
    "    t_interval = t_intervals[0],\n",
    "    tile_handler = \"single\", \n",
    "    merge_mode = \"merged\",\n",
    "    out_dir = True,\n",
    "    res = 100,\n",
    "    epsg = 32634\n",
    ")\n",
    "\n",
    "tester = Tester( \n",
    "    recipe = 'recipes/03_tconcatenated.json',\n",
    "    aoi_file = \"aois/polygon.geojson\",\n",
    "    t_interval = t_intervals[0],\n",
    "    tile_handler = \"single\", \n",
    "    merge_mode = \"merged\",\n",
    "    out_dir = True,\n",
    "    res = 100,\n",
    "    epsg = 32634\n",
    ")\n",
    "\n",
    "tester = Tester( \n",
    "    recipe = 'recipes/03_tconcatenated.json',\n",
    "    aoi_file = \"aois/multipolygon.geojson\",\n",
    "    t_interval = t_intervals[1],\n",
    "    tile_handler = \"single\", \n",
    "    merge_mode = \"merged\",\n",
    "    out_dir = True,\n",
    "    res = 100,\n",
    "    epsg = 32754\n",
    ")\n",
    "\n",
    "tester = Tester( \n",
    "    recipe = 'recipes/04_sconcatenated.json',\n",
    "    aoi_file = \"aois/polygon.geojson\",\n",
    "    t_interval = t_intervals[0],\n",
    "    tile_handler = \"single\", \n",
    "    merge_mode = \"merged\", \n",
    "    out_dir = False,\n",
    "    res = 100,\n",
    "    epsg = 32634\n",
    ")\n",
    "\n",
    "tester = Tester(\n",
    "    recipe = \"recipes/05_tgrouped.json\",\n",
    "    aoi_file = \"aois/multipolygon.geojson\",\n",
    "    t_interval = t_intervals[1],\n",
    "    tile_handler = \"single\", \n",
    "    merge_mode = \"merged\",\n",
    "    out_dir = True,\n",
    "    res = 100,\n",
    "    epsg = 32754\n",
    ")\n",
    "\n",
    "tester = Tester(\n",
    "    recipe = \"recipes/05_tgrouped.json\",\n",
    "    aoi_file = \"aois/multipoint.geojson\",\n",
    "    t_interval = t_intervals[1],\n",
    "    tile_handler = \"single\", \n",
    "    merge_mode = \"merged\",\n",
    "    out_dir = True,\n",
    "    res = 100,\n",
    "    epsg = 32632\n",
    ")\n",
    "\n",
    "tester = Tester( \n",
    "    recipe = 'recipes/06_sgrouped.json',\n",
    "    aoi_file = \"aois/polygon.geojson\",\n",
    "    t_interval = t_intervals[0],\n",
    "    tile_handler = \"single\", \n",
    "    merge_mode = \"merged\",\n",
    "    out_dir = True,\n",
    "    res = 100,\n",
    "    epsg = 32634\n",
    ")\n",
    "\n",
    "tester = Tester( \n",
    "    recipe = 'recipes/06_sgrouped.json',\n",
    "    aoi_file = \"aois/multipolygon.geojson\",\n",
    "    t_interval = t_intervals[0],\n",
    "    tile_handler = \"single\", \n",
    "    merge_mode = \"merged\",\n",
    "    out_dir = True,\n",
    "    res = 100,\n",
    "    epsg = 32754\n",
    ")\n",
    "\n",
    "tester = Tester(\n",
    "    recipe = \"recipes/07_tmulti_grouped.json\",\n",
    "    aoi_file = \"aois/polygon.geojson\",\n",
    "    t_interval = t_intervals[0],\n",
    "    tile_handler = \"single\", \n",
    "    merge_mode = \"vrt_shapes\",\n",
    "    out_dir = True,\n",
    "    res = 100,\n",
    "    epsg = 32634\n",
    ")\n",
    "\n",
    "tester = Tester(\n",
    "    recipe = \"recipes/08_tmulti_double_strat.json\",\n",
    "    aoi_file = \"aois/polygon.geojson\",\n",
    "    t_interval = t_intervals[0],\n",
    "    tile_handler = \"single\", \n",
    "    merge_mode = \"vrt_shapes\",\n",
    "    out_dir = True,\n",
    "    res = 100,\n",
    "    epsg = 32634\n",
    ")\n",
    "\n",
    "tester = Tester( \n",
    "    recipe = 'recipes/09_udf.json',\n",
    "    aoi_file = \"aois/polygon.geojson\",\n",
    "    t_interval = t_intervals[0],\n",
    "    tile_handler = \"single\", \n",
    "    merge_mode = \"merged\",\n",
    "    out_dir = True,\n",
    "    res = 100,\n",
    "    epsg = 32634\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopandas as gpd\n",
    "# polys = gpd.read_file(\"aois/multipolygon.geojson\").to_crs(32754)\n",
    "# polys.bounds[\"maxx\"] - polys.bounds[\"minx\"]\n",
    "# polys.bounds[\"maxx\"] - polys.bounds[\"minx\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
